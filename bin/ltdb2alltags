#!/usr/bin/python

import os, sys, csv, json
from argparse import ArgumentParser
import xml.etree.cElementTree as et
import palaso.langtags as lt
import csv, urllib2, codecs

useful_files = ['https://www.ethnologue.com/codes/LanguageIndex.tab',
                'https://www.ethnologue.com/codes/LanguageCodes.tab',
                'https://www.sil.org/iso639-3/iso-639-3.tab']

def find_file(tagstr, root='.') :
    fname = tagstr.replace('-', '_') + '.xml'
    testf = os.path.join(root, fname)
    if os.path.exists(testf) : return testf
    testf = os.path.join(root, fname[0], fname)
    if os.path.exists(testf) : return testf
    return None

def issimple(testf):
    try:
        doc = et.parse(testf)
    except:
        return False
    if len(doc.getroot()) > 1 : return False
    return True

def process_cldrentry(s, lts, allentries, root='.'):
    s = s.replace("_", "-")
    if s in lts:
        return
    l = lt.LangTag(s)
    if l.region is not None:
        t = lt.LangTag(tag=None, lang=l.lang, script=l.script, variants=l.variants, extensions=l.extensions)
        n = None
        if t in lts:
            n = lts[t]
        elif str(t) in allentries:
            if str(l.region) in allentries[str(t)][1]:
                n = allentries[str(t)][0]
        if n is not None:
            if l.script is None:
                l.script = n.script
                l.hidescript = True
        testf = find_file(str(t), root=root)
        if testf is not None:
            l.parent = t
            l.parentsame = issimple(find_file(s, root))
    lts.add(l)
    return l

parser = ArgumentParser()
parser.add_argument('infile', help='Input CSV file from Google drive')
parser.add_argument('outfile', help='alltags.txt output file')
parser.add_argument('-i','--indir', default='.', help='Directory containing sldr tree')
parser.add_argument('-p','--operators',action="store_true",default=False,help="Output complex operators")
parser.add_argument('-t','--text',action="store_true",default=False,help="Output text format")
args = parser.parse_args()

lts = lt.LangTags(noalltags=True)
deprecated = set()
for v in lts.values():
    if getattr(v, 'deprecated', False):
        deprecated.add(v.lang)
lts.clear()
allentries = {}
allmacros = {}
with open(args.infile) as csvfile :
    reader = csv.DictReader(csvfile)
    for row in reader :
#        if 'CLDR' in row['confirmed'] : continue
        lid = row['Lang_Id']
        ls = row['likely_subtag']
        i6 = row['ISO 639-3']
        macro = row['Macro']
        t = lt.LangTag(ls)
        b = lt.LangTag(lid)
        if b.script in [None, 'Zyyy', 'Qaax']:
            t.hidescript = True
        if b.region is None :
            t.hideregion = True
        t.hideboth |= (t.hideregion and t.hidescript)
        if t.lang in deprecated:
            t.deprecated = True
        lts.add(t)
        if repr(t) in lts:
            lts[repr(t)].iso639 = i6
        allentries[lid] = (t, row['regions'].split(' '))
        if macro != "":
            s = str(t)
            m = lt.LangTag(macro)
            m.merge_equivalent(t)
            allmacros[s] = repr(m)

for l in os.listdir(args.indir) :
    if l.endswith('.xml') :
        if 1 < len(l.split('_', 1)[0]) < 4 :
            process_cldrentry(l[:-4], lts, allentries, root=args.indir)
    elif len(l) == 1 and os.path.isdir(os.path.join(args.indir, l)) :
        for s in os.listdir(os.path.join(args.indir, l)) :
            if s.endswith('.xml') :
                if 1 < len(s.split('_', 1)[0]) < 4 :
                    process_cldrentry(s[:-4], lts, allentries, root=args.indir)

for k, v in allmacros.items():
    try:
        base = lts[k]
        macro = lts[v]
    except KeyError:
        macro = lt.LangTag(v)
        lts.add(macro)
        if base.script is None:
            macro.hidescript = True
        if base.region is None:
            macro.hideregion = True
    base.skip = True
    macro.base.append(base)

    
if args.text:
    with open(args.outfile, "w") as alltags :
        res = lts.generate_alltags()
        
        outstrings = []
        for line in res:
            lineres = [[" = ", x] for x in line if x]
            if not len(lineres):
                continue
            lineres[0][0] = ""
            hasstar = False
            for l in lineres:
                tf = find_file(l[1], root=args.indir)
                if tf is not None:
                    if hasstar:
                        if args.operators:
                            l[0] = " |= " if issimple(tf) else " <= "
    #                    else:
    #                        l[0] = " | "
                    elif args.operators and hasattr(lts.get(l[1], l[1]), "parent"):
                        x = lts[l[1]]
                        l[1] = l[1] + (" >| " if x.parentsame else " > ") + "*" + str(x.parent)
                    l[1] = "*" + l[1]
                    hasstar = True
            outstrings.append("".join(x[0] + x[1] for x in lineres))
        alltags.write("\n".join(sorted(outstrings, key=lambda x:x.replace('*', ''))) + "\n")
else:
    names = {}
    #namef = urllib2.urlopen("https://www.ethnologue.com/codes/LanguageIndex.tab")
    namef = open("LanguageIndex.tab", "r")
    reader = csv.DictReader(namef, dialect=csv.excel_tab)
    for r in reader:
        if r['NameType'].startswith("L") and r['CountryID'] and not r['NameType'].endswith("P"):
            names.setdefault(r['LangID']+"-"+r['CountryID'], [[],[]])[0 if r['NameType'] == 'L' else 1].append(r['Name'])
    namef.close()

    collisions = {}
    res = []
    for t in sorted(set(lts.values())):
        if t.skip:
            continue
        r = t.allforms()
        if not len(r[0]):
            continue
        n = {'tag': r[0], 'full': r[-1], 'region': t.region}
        if len(r) > 2:
            n['tags'] = r[1:-1]
        if hasattr(t, 'iso639'):
            n['iso639_3'] = t.iso639
        elif t.base is not None and hasattr(t.base, 'iso639'):
            n['iso639_3'] = t.base.iso639
        elif t.lang in lts:
            x = lts[t.lang]
            if hasattr(x, 'iso639'):
                n['iso639_3'] = x.iso639
        hassldr = False
        for l in r:
            if find_file(l, root=args.indir) is not None:
                hassldr = True
                break
        n['sldr'] = hassldr
        lname = "{}-{}".format(n.get('iso639_3', t.lang), t.region)
        if lname in names:
            n['name'] = names[lname][0][0]
            n['names'] = names[lname][1]
        if getattr(t, 'deprecated', False):
            n['deprecated'] = True
        res.append(n)
        if n['tag'] in collisions:
            print("Multiple entries for: {} = {}, {}".format(n['tag'], n['full'], collisions[n['tag']]))
        else:
            collisions[n['tag']] = n['full']
    with open(args.outfile, "w") as fh:
        json.dump(sorted(res, key=lambda x:x['tag']), fh, sort_keys=True, indent=4, ensure_ascii=False)


